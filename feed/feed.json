{
	"version": "https://jsonfeed.org/version/1.1",
	"title": "Brian&#39;s Blog",
	"language": "en",
	"home_page_url": "https://brianroberg.com/",
	"feed_url": "https://brianroberg.com/feed/feed.json",
	"description": "Thoughts on ideas concerning the church, society, and technology",
	"author": {
		"name": "Brian Roberg",
		"url": "https://brianroberg.com/about-me/"
	},
	"items": [
		{
			"id": "https://brianroberg.com/blog/ai-disruption-meaning/",
			"url": "https://brianroberg.com/blog/ai-disruption-meaning/",
			"title": "AI and Disruption",
			"content_html": "<p>I distinctly remember my first encounter with a large language model (LLM). It was sometime in early 2022, and I'd been hearing enough about GPT-3 (a forerunner of ChatGPT) that I wanted to try it out myself. So I took one of my recent ministry newsletters, pasted the first three-quarters of it into the prompt, and asked the model to compose a new conclusion.</p>\n<p>I was ready to be impressed if the model could bring the story to a coherent close. I was not ready for what it actually produced, which was something like:</p>\n<blockquote>\n<p>“We are truly grateful for your unwavering support that enables us to continue reaching out and making an impact on young lives like J.'s. This story is a testament to God's unfailing love and pursuit of His children, even in the darkest times…”<a href=\"https://brianroberg.com/blog/ai-disruption-meaning/\"><sup>1</sup></a></p>\n</blockquote>\n<p>What floored me was that the model not only picked up on the concrete <em>events</em> of the story, but also closed the letter by <em>casting vision</em> for the kingdom-building opportunities in campus ministry. In other words, it generated a paragraph that, until that point, I would have assumed could only have been produced by an articulate human writer.</p>\n<p>On an emotional level, as I read what the model produced I experienced that sinking sensation you get in your gut when you discover that something has gone terribly wrong. I may have even said a prayer in that moment along the lines of, &quot;Lord, have mercy.&quot;</p>\n<p>Why that response rather than the unalloyed excitement many others have felt? To be sure, I am excited about the technical possibilities offered by LLMs and other forms of AI.<a href=\"https://brianroberg.com/blog/ai-disruption-meaning/\"><sup>2</sup></a> I have spent many hours experimenting with LLMs and related tools since that first foray with GPT-3, and I'm convinced that there are many highly beneficial applications for these technologies. But I would also say that my &quot;Lord, have mercy&quot; prayer still captures my overall feeling about AI. I feel this way because I expect AI to be one of the most <em>disruptive</em> technologies of our time. Exploring that idea—disruption—is my purpose in this post.</p>\n<p>When I say that AI will be disruptive, I mean that it will bring about changes that increasingly display two characteristics:</p>\n<ol>\n<li>Impact: It will force <em>significant</em> changes to our social, cultural, and economic order.</li>\n<li>Speed: These changes will occur <em>quickly enough</em> that people and institutions will not be able to adapt smoothly, but will experience jarring discontinuity.</li>\n</ol>\n<p>When both of these characteristics are present, we experience a technology as disruptive. It's what we experienced in the 80's when the personal computer made rapid inroads into businesses of all sizes and &quot;computerization&quot; resulted in the obsolescence of entire categories of employment. We saw it again in the late aughts and early 10's when the smartphone put the world in everyone's pocket and rapidly re-ordered norms regarding what it means to be present in-person with someone.</p>\n<p>Having cited those recent examples, let me be clear that &quot;disruptive&quot; is not the same as &quot;destructive&quot; or &quot;morally wrong.&quot; While it's in our nature to experience rapid, significant change negatively, this doesn't mean that disruption is always bad. In other words, I'm not attempting to render a moral judgment on AI technology by labeling it &quot;disruptive.&quot; (It's vital that we learn to make moral judgments about AI, but it's not what I'm trying to do in this particular discussion.)</p>\n<p>In subsequent posts I'll flesh out particular ways in which I expect AI will be disruptive, but for the purpose of illustrating what disruption <em>means</em> let's consider one example of a disruption that is already well underway: students using LLMs to cheat on tests and papers.</p>\n<p>LLMs like ChatGPT have seriously undermined several important techniques that educators rely on for evaluating students' learning. As a philosophy major, I had several courses in which my grade was entirely based on papers, with not a single in-class quiz or exam the entire semester. I had other classes in which take-home tests were common. My professors ran their courses this way because it gave them low-cost yet reliable assessments of how well we understood the material. It was reliable because cheating was hard: in order to cheat on a paper, for instance, you would have to lift large sections of writing from someone else's paper. This is difficult to do, especially without being detected.</p>\n<p>The LLM has upended that picture entirely. Now, cheating on a paper or take-home exam—or just about <em>any</em> form of assessment in an online course—is trivial to do and near-impossible to detect. In the blink of an eye, several major tools in our educational system's toolbox were rendered at best problematic, perhaps even invalid.</p>\n<p>To assess the impact of this change, it's crucial to realize that this is not merely a technical or logistical concern. Students must now reckon with a temptation toward moral compromise that is much stronger than it was just a few years ago: the risk of cheating is low, the reward is high, and (perhaps even worse) the perception that “everyone else is doing it” could undermine the integrity of the entire grading system. This is not mere speculation. My organization's work is with college students, and they are telling us that cheating is a big part of their moral landscape now. This is a significant impact to arise from a technological change.</p>\n<p>As for the role speed plays in this disruption, imagine how different our situation would be if, instead of exploding onto the scene all at once in 2022, the technical capabilities of ChatGPT had appeared gradually over the course of 30 years. In this scenario:</p>\n<ul>\n<li>Most teachers would have experienced <em>as students</em> the temptation toward cheating with LLMs, and could apply that experience to the decisions they make about how to grade their courses.</li>\n<li>Students would have grown up learning about LLMs, how to distinguish between proper and improper uses of them, and perhaps would even have absorbed some of the moral consensus that would have been forming regarding their use.</li>\n<li>School districts and university faculties would have formed committees to examine the challenge from LLMs and issue recommendations for changes to grading practices.</li>\n<li>Academia as a whole would have time for conventional thinking about grading to change.</li>\n</ul>\n<p>As it is, none of that has happened. The fast uptake of ChatGPT after its public release meant that, for all practical purposes, the technological change happened instantly. Many (most?) educators are still assigning papers and take-home tests as if nothing had changed. (Just the other day, I spoke with a friend who is an instructor for an intro-level class at a major university. She estimated that half of her students are cheating on exams by using ChatGPT to generate answers. But she doesn't have the authority to change how the course is graded, and the professors who have the authority don't see any urgent need to change.)</p>\n<p>To really understand what I mean by disruption, however, we need to step back from this particular example to consider what the total effect of LLMs and other generative AI might be. After all, students cheating with LLMs is just one example in one segment of our society, and a relatively clear-cut example at that. But I believe that the nature of generative AI suggests that we will experience disruption in just about every area of life—and that in most cases the disruption will be harder to describe than the cheating example, but no less real.</p>\n<h2 id=\"footnotes\" tabindex=\"-1\">Footnotes <a class=\"header-anchor\" href=\"https://brianroberg.com/blog/ai-disruption-meaning/\">#</a></h2>\n<p><a id=\"fn1\"></a>\n1: I generated this example using the same newsletter I used then, but this time with an open source model running on my laptop.</p>\n<p><a id=\"fn2\"></a>\n2: N.B. from the Correct Terminology Department: Since the release of ChatGPT, most mainstream discourse has used the term “AI” as if it referred exclusively to forms of generative AI like LLMs and image generators. A more precise and historically accurate usage recognizes that “artificial intelligence” is a much broader discipline that was well-established within computer science by the mid-20th century. I will try to avoid use of “AI” that obscures this fact, but I am not going to be pedantic about it.</p>\n",
			"date_published": "2024-10-30T00:00:00Z"
		}
		,
		{
			"id": "https://brianroberg.com/blog/telling-a-better-story/",
			"url": "https://brianroberg.com/blog/telling-a-better-story/",
			"title": "Book Review: Telling a Better Story",
			"content_html": "<p><em>I wrote this review some time ago. I didn't post it because I was intending to write more, but looking it over now I think it's complete enough to share.</em></p>\n<p>The ostensible purpose of a book about apologetics is to help Christians persuade non-Christians of the truth of the gospel. But the nature of the subject makes it very challenging for a writer to achieve this goal. I've read apologetics books that feel like they were written in an ivory tower (i.e. they're too abstract). I've also read books that feel like they were written in a fortress (i.e. they're too adversarial). I've even read some that feel like they were written in a fortified ivory tower! Joshua D. Chatraw's 2020 book <em>Telling a Better Story</em> is a refreshing counterexample.</p>\n<p>My strongest praise for this book is that it feels like it was written in the same coffee shop where you might sit down for a conversation with a living, breathing, non-Christian neighbor. Chatraw accomplished this by consistently urging readers to pay attention to the person we're conversing with. &quot;Listening well&quot; was not one chapter of the book, but a constant refrain that appeared within every chapter. He conveyed this message in a tone of earnest pastoral counsel, with gentle yet insistent reminders throughout the book.</p>\n<p>This pastoral tone dovetailed well with what you might call the structural approach of the book, which Chatraw calls &quot;inside-out apologetics.&quot; In order to share the gospel in a way that people will actually hear, you need to first understand what the other person believes and values. Chatraw advocates thinking about these commitments in terms of stories—the narratives people use to make sense of the world and of their lives. Once you get inside someone's story, then you have a chance to tell the story of the gospel in a way that connects with what's actually important to that person.</p>\n<p>The key to this step (and the origin of the book's title) is recognizing that the gospel does a better job of addressing the needs and desires everyone feels. Much of the substance of the book traces this out along various dimensions with different issues. Take for example the issue of expressive individualism. Many books do a great job analyzing the effects of expressive individualism in our culture, and indeed this book gives a good introductory picture of the problem. But it also points out that just about everyone, though they might live out the tenets of expressive individualism in most aspects of their life, would vehemently defend the idea that certain relationships call for self-sacrifice for the sake of the other person. Expressive individualism can't account for self-sacrifice. The gospel can.</p>\n",
			"date_published": "2024-09-13T00:00:00Z"
		}
		,
		{
			"id": "https://brianroberg.com/blog/essentialism/",
			"url": "https://brianroberg.com/blog/essentialism/",
			"title": "Book Review: Essentialism by Greg McKeown",
			"content_html": "<p>It is possible to read Greg McKeown’s 2014 book <em>Essentialism: The Disciplined Pursuit of Less</em> as a collection of techniques for time management. There is some promise to this approach, as McKeown has gathered together a number of astute observations and suggestions to help readers better manage their priorities. But overall I believe that anyone who truly wants to improve their productivity would do better to skip this book.</p>\n<p>Before I describe where I see this book falling short, I'll give it credit for its strengths. There are some good reasons that people I respect have found this book valuable enough to make it required reading in DiscipleMakers’ staff training program.</p>\n<p>The principal strength of the book is that it unflinchingly presents the inescapability of trade-offs in decision-making. As Oliver Burkeman described in <a href=\"https://brianroberg.com/blog/four-thousand-weeks\"><em>Four Thousand Weeks,</em></a> there is a tendency among productivity gurus to promise that, if only you master their technique, you will be able to achieve all your life’s ambitions without having to say “no” to any deeply-held desires. McKeown rejects this false promise, early and often. In fact, the characteristic flaw of McKeown’s “Non-Essentialist” bogeyman is his inability (or unwillingness) to admit that we can only say “yes” to one thing by saying “no” to many other things.</p>\n<p>If realism about trade-offs is the main strength of the book, it also does a good job presenting various corollary arguments. For example, McKeown convincingly describes the dangers of over-optimistic planning and makes a good case for the importance of including buffer in our schedules. He provides a useful survey of research into cognitive biases that affect our decision-making. Also, his discussion of the value of routine and habit confirmed my inclination to read further on this topic. While there were points when his manner of presentation verges on the trivial, the book undoubtedly has some solid content.</p>\n<p>That said, my overall evaluation of the book is not positive. In fact, I feel I can't write about this book  without describing the magnitude of my subjective reaction to it. I found myself viscerally disliking the book to a degree I rarely experience. While many complaints come to mind, I will focus my critique to two points: one concerning style, the other a matter of more substance.</p>\n<p>Stylistically, I found McKeown's approach to his topic to be off-puttingly pretentious. As I've said, the book contains some solid content relating to time management and prioritization. But McKeown talks a much bigger game than that. He wants you to believe that Essentialism(TM) will transform your life and unlock a life of true fulfillment. He says this explicitly in his concluding chapter, but he works to build an aura of grandeur throughout the book. He often does this by associating his ideas with the lives of revered people, including Rosa Parks and Mohandas Gandhi. Or he draws (superficial) connections to the ideas of noted  thinkers. At one point he name-drops Aristotle and Heidegger in the same paragraph. But I found all this unconvincing. The overall impression is that of a business school student wearing a philosophy department sweatshirt.</p>\n<p>But my biggest objection with <em>Essentialism</em> is not its pretentious lack of substance. The substance it does have is even more troubling.</p>\n<p>Notwithstanding his puffed-up presentation, McKeown does make claims about what it means to live a virtuous life. The problem is that his system of ethics is thoroughly unbiblical. The highest ethical imperative for the Essentialist is not to love God or to love other people; it is to realize one's own ambitions. The Essentialist must steadfastly reject opportunities that do not advance his own interests, period. Self-sacrificial service is moral failure. And he doesn't merely imply this. He states it explicitly, and even strengthens his case by invoking respected figures like Peter Drucker who make the same claim. The instances in which he praises people for choosing to spend time with loved ones are not counter-examples, because in these cases the Essentialist has decided that investing in those relationships is what self-actualization looks like (for now).</p>\n<p>And here is why I believe that the technical merits of <em>Essentialism</em> do not make up for its faults: McKeown's  productivity advice and his self-centered framework are inextricably linked. While some chapters contain more self-advancement than others, this ethic is the foundation of the book. It's what gives McKeown leverage in his exhortations that we slim down our commitments. It's what allows him to propose heuristics like his &quot;90% Rule&quot; without getting bogged down in questions of justice for the people affected by our decisions (such as job applicants). It's how he can talk up the value of setting boundaries in relationships without troubling himself to distinguish the difference between enabling and helping. In sum, whenever the interests of another person start to impinge on a would-be Essentialist's personal agenda, he offers a license to write that person off like a bad debt.</p>\n<p>These considerations lead me to conclude that whatever assets the book may have, its liabilities far outweigh them. As I noted at the beginning, it comes closest if your aim is simply to gain some insight into techniques for time management. But if this is your goal, I suggest you would do better to go right to the source and read the <em>Harvard Business Review</em> articles that represent the wisdom of the business school world. If you want to go deeper with a book that explores the intersection of technique and biblical motivation, I'd suggest Matt Perman's <em>What's Best Next</em>. While it's been quite a while since I read that book,  I'm considering picking it up again. I suspect I may find even more value in it now by contrast with <em>Essentialism.</em></p>\n",
			"date_published": "2022-03-07T00:00:00Z"
		}
		,
		{
			"id": "https://brianroberg.com/blog/four-thousand-weeks/",
			"url": "https://brianroberg.com/blog/four-thousand-weeks/",
			"title": "Book Review: Four Thousand Weeks by Oliver Burkeman",
			"content_html": "<p>Every once in a while I've looked for a book that presents a cogent and intellectually honest case for finding meaning in life, but without reference to God. My various casual searches were thwarted by the fact that the most prominent books that are tagged as “atheist” tend towards polemic. Since most real people are not polemicists, I judged such books unhelpful for understanding the views of people I might actually talk to. I’d given up looking.</p>\n<p>I was reminded of this desire as I read Oliver Burkeman's new book, <em>Four Thousand Weeks: Time Management for Mortals</em>. As indicated by its subtitle, the nominal topic of the book is time management.  But the real scope of the book is both broader and deeper. In fact, I think a more accurate (if less marketable) subtitle would be something like <em>An Atheist’s Guide to Living Well.</em> In the end I concluded that this book delivers not only helpful insights related to time management, but also a broader perspective toward life that I found valuable to read even though I profoundly disagree with some of Burkeman’s basic premises.</p>\n<p>Burkeman takes it as a given that there is no God—at least no God about whom we can know enough that He should figure into any of our decision-making. But Burkeman’s tone is nothing like that of the strident atheists who sell books by railing against God. In fact, both times he quotes Scripture in the book he does so with a respectful tone (even if one of the quotes was taken out of context). But it was a verse of Scripture he did <em>not</em> quote which best captures a major part of Burkeman’s thesis. That verse is James 4:14: “Yet you do not know what tomorrow will bring. What is your life? For you are a mist that appears for a little time and then vanishes.”</p>\n<p>The principal virtue of this book is that it provides—in effect, if not by intent—a clear, thorough, and insightful exploration of the implications of James 4:14. The “four thousand weeks” of the title refers to the number of weeks (roughly) in an 80-year life span, and Burkeman does an excellent job calling out ways in which we tend to ignore the fact of our mortality—especially in the peculiar corner of the self-help publishing world that focuses on time management and productivity.</p>\n<p>Burkeman asserts that time management is a failed discipline, and not only because it doesn’t deliver on its promises in terms of objective productivity. The more fundamental problem with time management technique is the implicit promise that usually lies <em>behind</em> the technique: that if you just master the technique, you will achieve mastery over your life as well as freedom from the nagging feeling that your life is slipping through your fingers. Burkeman counters this seductive promise with hard reality. We are going to die. We are <em>finite beings</em> who are inescapably bound to limitations in time and opportunity. To the degree that time management promises that we can accomplish everything that’s important to us so that we’ll never have to say “no” to opportunities we’d really like to pursue—to that degree, time management is a delusion that disconnects us from reality and diminishes our lives.</p>\n<p>Burkeman is relentless in driving this home in one area of life after another. I lost track of how many times he said some variation of “This might sound bleak, but there’s freedom in acknowledging that it’s true.” I actually found this quite refreshing, as it reflects a pattern of argumentation that acknowledges that what we believe about ourselves doesn’t matter if our beliefs don’t conform to the true nature of reality. It also reflected his priorities in what he wanted to convey. He was clearly more interested in helping readers think clearly in the big picture than he was in teaching particular techniques. For example, whereas he mentioned David Allen once, he devoted several pages to discussing Martin Heidegger’s philosophy about man in relation to time.</p>\n<p>Not that the book was entirely ethereal. For instance, Burkeman suggested a litmus test for judging a particular time management technique: whether the technique helps you “neglect the right things.” Techniques are helpful insofar as they help surface the hard decisions about which opportunities to pursue and which to reject. On the other hand, he said, be wary of techniques that obscure or defer such decisions, and especially of those that deny that such decisions are necessary. (Though Burkeman did not call out many techniques by name, he did single out the “Big Rocks” illustration from Stephen Covey's book <em>First Things First</em>, calling it a “lie.”)</p>\n<p>Burkeman is similarly incisive in handling topics such as procrastination, attention, distraction, and rest. In each of these areas he went deeper than I had thought before and made connections I hadn’t made before. His discussion on these topics is worth the time of reading the book on its own.</p>\n<p>But as I mentioned earlier, the book is not so much <em>about</em> time management as that it uses time management as a rendezvous point for an expedition into the question of how to live life well. I will still commend Burkeman as a worthy guide in this endeavor, but with an important qualification. Christians who have a solid biblical understanding of who they are in relation to God and the world can benefit from Burkeman’s secular take on how to find meaning in life. People without a biblical grounding, however, could be led astray.</p>\n<p>In fact, if James 4:14 helps us see the virtues of this book, the following verse—James 4:15—serves as an indictment of its shortcomings. That verse says, “Instead you ought to say, ‘If the Lord wills, we will live and do this or that.’” Burkeman does not believe that God’s will should figure into our decision-making, so his guidance concerning the ultimate ground of our decision-making leads him to unbiblical conclusions. Like the Preacher of Ecclesiastes, he provides valuable insight regarding matters under the sun but has little to say about eternal matters.</p>\n<p>That said, I do want to credit Burkeman for his intellectual honesty. A less careful non-theist might assert that human life has inherent dignity and meaning, forgetting that for life to be <em>inherently</em> meaningful it must receive that meaning from something outside itself. (In the Christian conception, every person has dignity and purpose because every person is created in the image of God.) Burkeman, in contrast, shoulders the harder work of carving out a path for a person to imbue his own life with meaning in the midst of an indifferent universe. (He does this along existentialist lines, investing tremendous weight in the sanctity of human self-determination.)</p>\n<p>In sum, I would recommend <em>Four Thousand Weeks</em> to anyone looking to better understand the constraints we face as limited creatures. It is a rare book that earnestly seeks meaning in life while taking care not to smuggle in ideas that derive from some form of theism. Within these constraints (i.e. under the sun) it offers wisdom. In addition, its vivid picture of the struggle to construct meaning for one’s own life could also help Christians as they share with their secular friends how the gospel expands the horizon of our lives.</p>\n",
			"date_published": "2022-01-31T00:00:00Z"
		}
		
	]
}
